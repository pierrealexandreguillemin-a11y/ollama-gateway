# Configuration Claude-Code / Continue.dev

## Gateway opÃ©rationnel âœ…

Votre gateway tourne sur **http://localhost:4000** avec routing intelligent automatique.

## Configuration Continue.dev (VSCode)

### 1. Ouvrir la configuration

`Ctrl+Shift+P` â†’ "Continue: Open config.json"

### 2. Ajouter le modÃ¨le

```json
{
  "models": [
    {
      "title": "ðŸ¤– Ollama Local (Auto-Routing)",
      "provider": "openai",
      "model": "auto",
      "apiBase": "http://localhost:4000/v1",
      "apiKey": "not-needed"
    }
  ]
}
```

### 3. Utiliser

`Ctrl+L` â†’ SÃ©lectionner "ðŸ¤– Ollama Local (Auto-Routing)" â†’ Posez vos questions !

---

## Configuration Cursor

### Settings â†’ Models â†’ Add Custom Model

- **Provider**: OpenAI Compatible
- **Base URL**: `http://localhost:4000/v1`
- **Model**: `auto`
- **API Key**: laissez vide ou `not-needed`

---

## Test Direct

### Depuis un terminal

```bash
# Question de code
curl -X POST http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "auto",
    "messages": [
      {"role": "user", "content": "Write a Python function to calculate factorial"}
    ]
  }'
```

**RÃ©sultat** : Route automatiquement vers **deepseek-coder-v2**

```bash
# Question d'Ã©checs
curl -X POST http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "auto",
    "messages": [
      {"role": "user", "content": "What is the best response to 1.e4?"}
    ]
  }'
```

**RÃ©sultat** : Route automatiquement vers **deepseek-chess**

---

## Endpoints Disponibles

### OpenAI-Compatible

- `POST /v1/chat/completions` - Chat avec routing auto
- `GET /v1/models` - Liste des modÃ¨les

### Gateway-Specific

- `GET /health` - Ã‰tat de santÃ©
- `GET /gateway/models` - Configuration
- `POST /gateway/route` - Tester le routing

---

## Workflow Optimal

**Avant** :
```
Vous â†’ Question â†’ Claude API â†’ $$$ tokens
```

**Maintenant** :
```
Vous â†’ Question code â†’ Continue/Claude-Code â†’ Gateway â†’ deepseek-coder â†’ RÃ©ponse
```

**Ã‰conomie** : ~10-20x moins de tokens Claude

---

## Exemples de Routing

| Prompt | ModÃ¨le SÃ©lectionnÃ© | Raison |
|--------|-------------------|---------|
| "Write Python code" | deepseek-coder-v2 | Matched: python, code |
| "Explain chess opening" | deepseek-chess | Matched: chess, opening |
| "Translate to French" | qwen2.5 | Matched: translate |
| "Write a story" | gemma2 | Matched: creative, write |
| "Quick answer" | llama3.2 | Matched: quick, fast |
| Autre | mistral | Default |

---

## Logs en Temps RÃ©el

Le gateway affiche les dÃ©cisions de routing :

```
2025-01-18 10:30:15 - INFO - Routing: deepseek-coder-v2:latest - Best for coding (matched: python, code)
```

---

## ArrÃªt du Gateway

```bash
# Trouver le processus
ps aux | grep "python main.py"

# ArrÃªter
kill <PID>

# Ou Ctrl+C dans le terminal si lancÃ© en premier plan
```

---

## RedÃ©marrage

```bash
cd C:\Dev\ollama-gateway
python main.py
```

---

## Prochaines Ã‰tapes (P1)

Dashboard autonome avec :
- Interface conversationnelle
- Visualisation temps rÃ©el
- Statistiques d'utilisation
- Historique conversations
- Lancement double-clic

Ã€ dÃ©finir ensemble !
